{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data-exploration-basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9nC5_RwqJcx"
      },
      "source": [
        "# Introduction to Data Exploration\n",
        "**Learning Objective:** \n",
        "- Learn to load a dataset\n",
        "- Learn to explore and visualise variables\n",
        "- Get familiar with common data exploration functions\n",
        "\n",
        "## The Data Science Pipeline\n",
        "\n",
        "![](https://mickaeltemporao.github.io/itds/images/pipeline.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sofsPeRDqNRO"
      },
      "source": [
        "## Data Acquisition\n",
        "With some Python basics we will start combining existing packages to acquire, and explore data.\n",
        "\n",
        "\n",
        "Before we can start looking into data, we need to load data into our machines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTx-1l9i4MPy"
      },
      "source": [
        "# Load the required libraries\n",
        "import pandas as pd\n",
        "# Let's load real-world data with pandas\n",
        "data_url = \"https://raw.githubusercontent.com/datamisc/ts-2020/main/data.csv\"\n",
        "anes_data  = pd.read_csv(data_url, compression='gzip')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGo1JjbCajS5"
      },
      "source": [
        "### Hack-Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM1yRUnDalfT"
      },
      "source": [
        "# What is the type of anes_data?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjjHzk6HXvgY"
      },
      "source": [
        "### Data Frames\n",
        "\n",
        "Data Frames are lists (or series when using pandas) that are put together in a table.\n",
        "\n",
        "![](https://storage.googleapis.com/lds-media/images/series-and-dataframe.width-1200.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxan1N8bZ-ig"
      },
      "source": [
        "# A quick example\n",
        "\n",
        "turnout = [66.8, 55.7, 54.9, 58.2, 56.7, 51.2, 49.0]\n",
        "year = [2020, 2016, 2012, 2008, 2004, 2000, 1996]\n",
        "party = [\"Dem\", \"Rep\", \"Dem\", \"Dem\", \"Rep\", \"Rep\", \"Dem\"]\n",
        "\n",
        "# We are creating a data frame from scratch\n",
        "my_data = pd.DataFrame(\n",
        "    {\n",
        "        'turnout': turnout,\n",
        "        'year': year,\n",
        "        'party': party,\n",
        "    }\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl4Ae1YLcn35"
      },
      "source": [
        "# What is the type of `my_data`\n",
        "type(my_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxI12tkYbgHQ"
      },
      "source": [
        "# Take a look at new dataset you just created\n",
        "my_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hsjrwPXdIkc"
      },
      "source": [
        "# We can also learn about the number of rows and columns of the dataset \n",
        "# by using the `.shape` attribute.\n",
        "my_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtLtKNiLdXHx"
      },
      "source": [
        "# When your dataset is too long might just want to print the first couple \n",
        "# observations (rows) by using the `.head()` method.\n",
        "my_data.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trP4mKZmdDEC"
      },
      "source": [
        "### Hack-Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HUmTMXtd2Fh"
      },
      "source": [
        "# What is the shape of the ANES dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEwdBpyOejCx"
      },
      "source": [
        "# Take a look at the head of the ANES data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA9ntSZReuBd"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Now that you have your data, you need to start getting familiar with your data. \n",
        "\n",
        "Most of the time you will be interested some specific concepts. So you need a way to select the variables related to your concepts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzxO4FXnfRb6"
      },
      "source": [
        "# The `columns` attribute allows you to get the column names of a dataframe\n",
        "anes_data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkHVVo1bf0A2"
      },
      "source": [
        "Let's say you are only interested knowing the candidate who people intend to vote for (V201033).\n",
        "\n",
        "We can use square brackets to select a single column!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL8_tCSygqbF"
      },
      "source": [
        "# Selecting the voting intent variable\n",
        "anes_data[\"V201033\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ruHSNNhYPU"
      },
      "source": [
        "# We can also save it in a new object and check it's type\n",
        "vote_int = anes_data[\"V201033\"]\n",
        "type(vote_int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZeNcun7h34Y"
      },
      "source": [
        "Series and Data Frames provide very useful methods to quickly learn about the data. Here a some common ones\n",
        "\n",
        "- `mean()`\n",
        "- `std()`\n",
        "- `min()`\n",
        "- `max()`\n",
        "- `describe()`\n",
        "- `value_counts()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoJiu6FzhzDX",
        "outputId": "350cb8e9-e45e-420f-ca1b-641f4b44cf9a"
      },
      "source": [
        "vote_int.describe()\n",
        "\n",
        "anes_data[\"V201033\"].between(1,2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        True\n",
              "1       False\n",
              "2        True\n",
              "3        True\n",
              "4        True\n",
              "        ...  \n",
              "8275     True\n",
              "8276     True\n",
              "8277     True\n",
              "8278    False\n",
              "8279     True\n",
              "Name: V201033, Length: 8280, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH-pHEcDhs7C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHbwTF39Wize"
      },
      "source": [
        "- Basic Data Exploration\n",
        "    - columns\n",
        "    - counts\n",
        "    - dtypes\n",
        "\n",
        "## Data Visualisation\n",
        "\n",
        "    - discrete\n",
        "    - continuous\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMxRLu0re2_e"
      },
      "source": [
        "## Types of data\n",
        "\n",
        "We have seen that there are different types of data in python (strings, integers, floats, booleans, ...). When doing research we can group data in two broad families:\n",
        "\n",
        "**Discrete** data can only take a finite number of values.\n",
        "\n",
        "- eg. The number of students in a class.\n",
        "\n",
        "**Continuous** data can take an infinite number of values.\n",
        "\n",
        "- eg. The height of a student.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi8CqadakRDC"
      },
      "source": [
        "# Filtering data\n",
        "vote_int = \"V201033\"  # The name of the voting intentions variables in the ANES\n",
        "mask = (df[vote_int] > 0) & (df[vote_int] < 5)  # Keeping relevant observations\n",
        "\n",
        "# Summarizing the data\n",
        "tmp_data = df[vote_int].loc[mask].replace(\n",
        "    {1:\"Biden\", 2:\"Trump\", 3:\"Jorgensen\", 4:\"Hawkins\"}\n",
        ").value_counts(\n",
        "    normalize=True\n",
        ")\n",
        "\n",
        "# Making a plot/graphic/figure\n",
        "tmp_data.plot.bar(\n",
        "    title=\"Voting Intentions\", \n",
        "    ylabel=\"Percentage\",\n",
        ");\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlqQzI8R5Zz3"
      },
      "source": [
        "# Extract tables and convert the html tables into pd.DataFrame()\n",
        "df = pd.read_html(html)[0].iloc[2:,:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KIE5UUg5cu7"
      },
      "source": [
        "## Cleaning Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9n7kcR4dLTb"
      },
      "source": [
        "# Inspect the data\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjUNJ9Ba5iln"
      },
      "source": [
        "# We notice that there seems to be a double header\n",
        "df.columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK6ERcta5jWT"
      },
      "source": [
        "# What is the type of columns\n",
        "type(df.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA2JYlIe5kcC"
      },
      "source": [
        "# Let's use a loop to extract and edit each element of the MultiIndex dataframe\n",
        "columnn_names = []\n",
        "for c in df.columns:\n",
        "    tmp = c[0].lower()\n",
        "    columnn_names.append(tmp.replace(\" \", \"_\"))\n",
        "\n",
        "columnn_names\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrBVR0gU5lUK"
      },
      "source": [
        "# Let's use regular expressions in a list comprehension this time\n",
        "import re\n",
        "regex = \"[a-z]+\"\n",
        "columnn_names = [\"_\".join(re.findall(regex, i)) for i in columnn_names]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmGVxVMs5l3h"
      },
      "source": [
        "# Let's edit the columns of our dataset\n",
        "df.columns = columnn_names\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSoXadEo5mXQ"
      },
      "source": [
        "# Let's further rename those columns\n",
        "names_dict = {\n",
        "    \"polling_firm\": \"source\",\n",
        "    \"last_dateof_polling\": \"date\",\n",
        "    \"samplesize\": \"sample_size\",\n",
        "    \"marginof_error\": \"error\",\n",
        "    \"cons\": \"cpc\",\n",
        "    \"liberal\": \"lpc\",\n",
        "    \"green\": \"gpc\",\n",
        "    \"polling_method\": \"method\",\n",
        "}\n",
        "\n",
        "type(names_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gke_V1T5nRh"
      },
      "source": [
        "# Pass the new dictionary as an argument to the .rename method\n",
        "df.rename(columns=names_dict, inplace=True)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9V7ryxd5n2h"
      },
      "source": [
        "# Let's check the data types\n",
        "df.dtypes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkoKzrsj5ppH"
      },
      "source": [
        "# The date field needs to be converted\n",
        "df[['date']] = pd.to_datetime(df.date)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJd2dc2Y5qWE"
      },
      "source": [
        "# We should also only keep the numeric values for the margins of error\n",
        "regex = \"(\\d+\\.*\\d*)\"\n",
        "df.error = df.error.str.extract(regex)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY-ZCGVA5q7U"
      },
      "source": [
        "# Let's look again at our dataset\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS93D1r55rbv"
      },
      "source": [
        "# What if we look at a random subsample\n",
        "df.sample(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GIcT7Pq5r4W"
      },
      "source": [
        "# Let's clean the sample\n",
        "regex = r\"\\(.*\\)\"\n",
        "df.sample_size = df.sample_size.str.replace(regex, \"\")\n",
        "df.sample_size = df.sample_size.str.replace(\" |,\", \"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iU8LAAX5tjx"
      },
      "source": [
        "# How does the data look now?\n",
        "df.sample(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eaf8vO05uuZ"
      },
      "source": [
        "# What about the data types?\n",
        "df.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HADs6lW5vmB"
      },
      "source": [
        "# Which of these variables are still objects?\n",
        "df.select_dtypes(include='object')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXgXmeb5yC3"
      },
      "source": [
        "# Let's use a dictionary to recode the data types\n",
        "convert_dict = {\n",
        "    'error': float,\n",
        "    'sample_size': int,\n",
        "    'lead': float\n",
        "}\n",
        "\n",
        "df = df.astype(convert_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUku2bRB5y4D"
      },
      "source": [
        "# Let's look once again at our data\n",
        "df.sample(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i84Qzw2W5zaf"
      },
      "source": [
        "# What are the remaining objects?\n",
        "df.select_dtypes(include='object')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S14uJehz5z_8"
      },
      "source": [
        "# Keep only necessary variables by creating a variable filter\n",
        "to_keep = [\n",
        "    'source',\n",
        "    'date',\n",
        "    'lpc',\n",
        "    'cpc',\n",
        "    'ndp',\n",
        "    'bq',\n",
        "    'gpc',\n",
        "    'ppc',\n",
        "    'method'\n",
        "]\n",
        "\n",
        "df = df[to_keep]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jc2nEBV7SaA"
      },
      "source": [
        "## Data IO\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IHjSTOddkIx"
      },
      "source": [
        "# Save the cleaned dataframe to a file\n",
        "file_name = \"national_polls_2019.csv\"\n",
        "df.to_csv(file_name, index=False)\n",
        "print(df)\n",
        "\n",
        "df.dtypes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWw_gIt07TLE"
      },
      "source": [
        "# Read the data back-in from the recorded csv file.\n",
        "\n",
        "# More info on read_csv\n",
        "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
        "df = pd.read_csv(\"national_polls_2019.csv\", parse_dates=['date'])\n",
        "df.dtypes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpZQqLUB7Zxr"
      },
      "source": [
        "## Data Exploration and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDoOasNpdr6D"
      },
      "source": [
        "# Let's convert this into a time-series dataframe\n",
        "df.set_index('date', inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcaAaVWD7ch7"
      },
      "source": [
        "# Time-series data should be stored in descending order\n",
        "df = df.sort_values(by=['date', 'source'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDLa0Ws_7c_W"
      },
      "source": [
        "# How does the data look now?\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIMp9oU07eXZ"
      },
      "source": [
        "# What about the tail?\n",
        "df.tail()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXfA8snl7ezQ"
      },
      "source": [
        "# A time indexed data frame provides much more control over the data\n",
        "df.loc[df.index > '2019-10-15']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgCuP_EU7fOG"
      },
      "source": [
        "# We can look at a single party\n",
        "df.lpc.loc['2019-10-20']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h96QxTsi7gBd"
      },
      "source": [
        "# We can focus on a subset of columns\n",
        "parties = [\"lpc\", \"cpc\", \"ndp\", \"bq\", \"gpc\", \"ppc\"]\n",
        "df.loc[:, parties]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXkeJ4CE7ggt"
      },
      "source": [
        "# We can aggregate/resample the data\n",
        "df[parties].resample('D', how='mean').head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnKK-ba07g-E"
      },
      "source": [
        "# We can also use pandas to plot\n",
        "df[parties].resample('D', how='mean').plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R30Sw-VXb1KC"
      },
      "source": [
        "\n",
        "### Anatomy of a Figure\n",
        "![Anatomy of a Figure](https://matplotlib.org/3.1.1/_images/anatomy.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gJjUSkR7hYj"
      },
      "source": [
        "# We can look at the distributions for each party\n",
        "df[parties].plot(kind='kde')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4_ZrItD7iDm"
      },
      "source": [
        "# Or do a simple box-plot\n",
        "df[parties].boxplot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZykjhTV7iei"
      },
      "source": [
        "# Let's look at missing values\n",
        "df.isnull().mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvyYBoaa7i72"
      },
      "source": [
        "# We can remove missing values\n",
        "df.dropna()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4IlZuOX7jou"
      },
      "source": [
        "# We just lost half of our dataset...\n",
        "# Maybe we should fill the missing values\n",
        "tmp_df = df.fillna(method='ffill', limit=3).copy()\n",
        "tmp_df.isnull().mean()\n",
        "\n",
        "df = tmp_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu5b5Dtx7kTu"
      },
      "source": [
        "# Let's investigate which polling firms have been most active\n",
        "df.source.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLZIK8ik7k-g"
      },
      "source": [
        "# Remove the firms that released less than 5 polls\n",
        "tmp_mask = df.source.value_counts() >= 5\n",
        "mask = tmp_mask.index[tmp_mask]\n",
        "\n",
        "df = df[df.source.isin(mask)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hn75nR57ll_"
      },
      "source": [
        "# Once again we could decide to visualize directly the result\n",
        "df.source.value_counts().plot(kind='barh')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8f6prY87mPR"
      },
      "source": [
        "# Try to do grouped operations and see how did each of these firms portrayed the liberal party\n",
        "df.groupby('source').lpc.describe().sort_values(by='mean')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFhQ0vrt7mvU"
      },
      "source": [
        "# We can also look at the means for all the parties\n",
        "df.groupby('source')[parties].mean().sort_values('lpc')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXft9CUK7nZ_"
      },
      "source": [
        "# We can also apply custom functions by groups\n",
        "z_score = lambda x: (x-x.mean()) / x.std()\n",
        "df.reset_index().groupby('source')[parties].apply(z_score).head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsuHM2tt7oCX"
      },
      "source": [
        "# Most algorithms need you to shape the date in a long format\n",
        "long_df = pd.melt(\n",
        "    df.reset_index(),\n",
        "    id_vars=['date', 'source'],\n",
        "    value_vars=parties,\n",
        "    var_name='party',\n",
        "    value_name='share',\n",
        ")\n",
        "\n",
        "long_df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAamHM8f7qmT"
      },
      "source": [
        "# Seaborn, a statistical data visualization library uses long-format\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
        "\n",
        "sns.swarmplot(\n",
        "    x=\"party\",\n",
        "    y=\"share\",\n",
        "    hue=\"source\",\n",
        "    data=long_df,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1x73YzS7ud-"
      },
      "source": [
        "# What if we need to add the sample size back?\n",
        "new_df = long_df.merge(\n",
        "    df[['method', 'source']].reset_index(),\n",
        "    on=['date', 'source']\n",
        ")\n",
        "\n",
        "new_df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxCX7w2j7vDh"
      },
      "source": [
        "# We can also expand the dataframe back to a wide format\n",
        "new_df = new_df.pivot_table(\n",
        "    index=['date', 'source', 'method'],\n",
        "    columns='party',\n",
        "    values='share',\n",
        ")\n",
        "\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}